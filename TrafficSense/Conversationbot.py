from rich import print
from typing import Any, List
from langchain.agents import Tool, create_react_agent, AgentExecutor
from langchain_openai import AzureChatOpenAI,ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from typing import Union

class ConversationBot:
    def __init__(
            self, llm: Union[ChatOpenAI,AzureChatOpenAI], toolModels: List,
            customedPrefix: str, verbose: bool = False
    ) -> Any:
        tools = []

        for ins in toolModels:
            """åˆå§‹åŒ–å·¥å…·é“¾ æ¯ä¸ªinsæ˜¯ä¸€ä¸ªå®ç°äº†inferenceæ–¹æ³•çš„class"""
            func = getattr(ins, 'inference')
            # å¢å¼ºå·¥å…·æè¿°ï¼Œå¸®åŠ©ReActæ›´å¥½åœ°é€‰æ‹©å·¥å…·
            tools.append(
                Tool(
                    name=func.name,
                    description=func.description,
                    func=func
                )
            )
        # ä½¿ç”¨ReAct Agentæ›¿ä»£ZeroShotAgent
        self.agent_memory = ConversationBufferMemory(memory_key="chat_history")
        
        # åˆ›å»ºäº¤é€šä¸“ä¸šçš„prompt template
        traffic_react_template = """
{customedPrefix}

ğŸš¦ ä½œä¸ºäº¤é€šåˆ†æä¸“å®¶ï¼Œè¯·éµå¾ªä»¥ä¸‹æ¨ç†æ¨¡å¼ï¼š

You have access to the following tools:
{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do as a traffic expert. Consider:
- What traffic data or analysis is needed?
- What is the logical sequence of actions?
- Do I need current status before optimization?
- Should I verify results after changes?
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

ğŸ” äº¤é€šåˆ†ææœ€ä½³å®è·µï¼š
- åˆ†æå‰å…ˆè·å–å½“å‰çŠ¶æ€
- ä¼˜åŒ–å‰å¿…é¡»äº†è§£é—®é¢˜æ‰€åœ¨
- ä¼˜åŒ–åè¦éªŒè¯æ”¹è¿›æ•ˆæœ
- æŠ¥å‘Šä¸­è¦åŒ…å«æ•°æ®æ”¯æ’‘å’Œæ–‡ä»¶è·¯å¾„

Begin!

Question: {input}
Thought:{agent_scratchpad}"""

        # ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿
        prompt = PromptTemplate.from_template(traffic_react_template)
        prompt = prompt.partial(customedPrefix=customedPrefix)
        
        agent = create_react_agent(llm, tools, prompt)
        self.agent_chain = AgentExecutor(
            agent=agent, 
            tools=tools,
            verbose=verbose,
            memory=self.agent_memory,
            max_iterations=12, 
            early_stopping_method="generate",
            handle_parsing_errors="Use the LLM output directly as your final answer!"
        )
    def dialogue(self, input: str):
        print('TransGPT is running with ReAct reasoning, Please wait for a moment...')
        res = self.agent_chain.invoke(
                {"input":input}
            )
        # print('History: ', self.agent_memory.buffer)
        return res["output"]
